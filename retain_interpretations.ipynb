{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import load_model, Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.constraints import Constraint\n",
    "from keras.utils.data_utils import Sequence\n",
    "import sys,os,argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_model(path):\n",
    "    \"\"\"Import model from given path and assign it to appropriate devices\"\"\"\n",
    "    K.clear_session()\n",
    "    config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    tfsess = tf.Session(config=config)\n",
    "    K.set_session(tfsess)\n",
    "    model = load_model(path, custom_objects={'FreezePadding':FreezePadding,\n",
    "                                             'FreezePadding_Non_Negative':FreezePadding_Non_Negative})\n",
    "    print(model.outputs)\n",
    "    model_with_attention = Model(model.inputs, model.outputs +\\\n",
    "                                              [model.get_layer(name='softmax_1').output,\\\n",
    "                                               model.get_layer(name='beta_dense_0').output])\n",
    "    return model, model_with_attention\n",
    "\n",
    "def get_model_parameters(model):\n",
    "    \"\"\"Extract model arguments that were used during training\"\"\"\n",
    "    class ModelParameters:\n",
    "        \"\"\"Helper class to store model parametesrs in the same format as ARGS\"\"\"\n",
    "        def __init__(self):\n",
    "            self.num_codes = None\n",
    "            self.numeric_size = None\n",
    "            self.use_time = None\n",
    "            self.emb_weights = None\n",
    "            self.output_weights = None\n",
    "            self.bias = None\n",
    "\n",
    "\n",
    "    params = ModelParameters()\n",
    "    names = [layer.name for layer in model.layers]\n",
    "    params.num_codes = model.get_layer(name='embedding').input_dim-1\n",
    "    params.emb_weights = model.get_layer(name='embedding').get_weights()[0]\n",
    "    params.output_weights, params.bias = model.get_layer(name='time_distributed_out').get_weights()\n",
    "    print('Model bias: {}'.format(params.bias))\n",
    "    if 'numeric_input' in names:\n",
    "        params.numeric_size = model.get_layer(name='numeric_input').input_shape[2]\n",
    "        #Add artificial embeddings for each numeric feature and extend the embedding weights\n",
    "        #Numeric embeddings is just 1 for 1 dimension of the embedding which corresponds to taking value as is\n",
    "        numeric_embeddings = np.zeros((params.numeric_size, params.emb_weights.shape[1]+params.numeric_size))\n",
    "        for i in range(params.numeric_size):\n",
    "            numeric_embeddings[i, params.emb_weights.shape[1]+i] = 1\n",
    "        #Extended embedding is original embedding extended to larger output size and numerics embeddings added\n",
    "        params.emb_weights = np.append(params.emb_weights,\n",
    "                                       np.zeros((params.num_codes+1, params.numeric_size)),\n",
    "                                       axis=1)\n",
    "        params.emb_weights = np.append(params.emb_weights, numeric_embeddings, axis=0)\n",
    "    else:\n",
    "        params.numeric_size = 0\n",
    "    if 'time_input' in names:\n",
    "        params.use_time = True\n",
    "    else:\n",
    "        params.use_time = False\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreezePadding_Non_Negative(Constraint):\n",
    "    \"\"\"Freezes the last weight to be near 0 and prevents non-negative embeddings\"\"\"\n",
    "    def __call__(self, w):\n",
    "        other_weights = K.cast(K.greater_equal(w, 0)[:-1], K.floatx())\n",
    "        last_weight = K.cast(K.equal(K.reshape(w[-1, :], (1, K.shape(w)[1])), 0.), K.floatx())\n",
    "        appended = K.concatenate([other_weights, last_weight], axis=0)\n",
    "        w *= appended\n",
    "        return w\n",
    "class FreezePadding(Constraint):\n",
    "    \"\"\"Freezes the last weight to be near 0.\"\"\"\n",
    "    def __call__(self, w):\n",
    "        other_weights = K.cast(K.ones(K.shape(w))[:-1], K.floatx())\n",
    "        last_weight = K.cast(K.equal(K.reshape(w[-1, :], (1, K.shape(w)[1])), 0.), K.floatx())\n",
    "        appended = K.concatenate([other_weights, last_weight], axis=0)\n",
    "        w *= appended\n",
    "        return w    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SequenceBuilder(Sequence):\n",
    "    \"\"\"Generate Batches of data\"\"\"\n",
    "    def __init__(self, data, model_parameters, ARGS):\n",
    "        #Receive all appropriate data\n",
    "        self.codes = data[0]\n",
    "        index = 1\n",
    "        if model_parameters.numeric_size:\n",
    "            self.numeric = data[index]\n",
    "            index += 1\n",
    "\n",
    "        if model_parameters.use_time:\n",
    "            self.time = data[index]\n",
    "\n",
    "        self.num_codes = model_parameters.num_codes\n",
    "        self.batch_size = ARGS.batch_size\n",
    "        self.numeric_size = model_parameters.numeric_size\n",
    "        self.use_time = model_parameters.use_time\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Compute number of batches.\n",
    "        Add extra batch if the data doesn't exactly divide into batches\n",
    "        \"\"\"\n",
    "        if len(self.codes)%self.batch_size == 0:\n",
    "            return len(self.codes) // self.batch_size\n",
    "        return len(self.codes) // self.batch_size+1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get batch of specific index\"\"\"\n",
    "        def pad_data(data, length_visits, length_codes, pad_value=0):\n",
    "            \"\"\"Pad data to desired number of visiits and codes inside each visit\"\"\"\n",
    "            zeros = np.full((len(data), length_visits, length_codes), pad_value)\n",
    "            for steps, mat in zip(data, zeros):\n",
    "                if steps != [[-1]]:\n",
    "                    for step, mhot in zip(steps, mat[-len(steps):]):\n",
    "                        #Populate the data into the appropriate visit\n",
    "                        mhot[:len(step)] = step\n",
    "\n",
    "            return zeros\n",
    "        #Compute reusable batch slice\n",
    "        batch_slice = slice(idx*self.batch_size, (idx+1)*self.batch_size)\n",
    "        x_codes = self.codes[batch_slice]\n",
    "        #Max number of visits and codes inside the visit for this batch\n",
    "        pad_length_visits = max(map(len, x_codes))\n",
    "        pad_length_codes = max(map(lambda x: max(map(len, x)), x_codes))\n",
    "        #Number of elements in a batch (useful in case of partial batches)\n",
    "        length_batch = len(x_codes)\n",
    "        #Pad data\n",
    "        x_codes = pad_data(x_codes, pad_length_visits, pad_length_codes, self.num_codes)\n",
    "        outputs = [x_codes]\n",
    "        #Add numeric data if necessary\n",
    "        if self.numeric_size:\n",
    "            x_numeric = self.numeric[batch_slice]\n",
    "            x_numeric = pad_data(x_numeric, pad_length_visits, self.numeric_size, -99.0)\n",
    "            outputs.append(x_numeric)\n",
    "        #Add time data if necessary\n",
    "        if self.use_time:\n",
    "            x_time = sequence.pad_sequences(self.time[batch_slice],\n",
    "                                            dtype=np.float32, maxlen=pad_length_visits,\n",
    "                                            value=+99).reshape(length_batch, pad_length_visits, 1)\n",
    "            outputs.append(x_time)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def read_data(model_parameters, path_data, path_dictionary):\n",
    "    \"\"\"Read the data from provided paths and assign it into lists\"\"\"\n",
    "    data = pd.read_pickle(path_data)\n",
    "    data_output = [data['codes'].values]\n",
    "\n",
    "    if model_parameters.numeric_size:\n",
    "        data_output.append(data['numerics'].values)\n",
    "    if model_parameters.use_time:\n",
    "        data_output.append(data['to_event'].values)\n",
    "\n",
    "    with open(path_dictionary, 'rb') as f:\n",
    "        dictionary = pickle.load(f)\n",
    "\n",
    "    dictionary[model_parameters.num_codes] = 'PADDING'\n",
    "    return data_output, dictionary\n",
    "\n",
    "def get_importances(alphas, betas, patient_data, model_parameters, dictionary):\n",
    "    \"\"\"Construct dataframes that interpret each visit of the given patient\"\"\"\n",
    "    importances = []\n",
    "    codes = patient_data[0][0]\n",
    "    index = 1\n",
    "    if model_parameters.numeric_size:\n",
    "        numerics = patient_data[index][0]\n",
    "        index += 1\n",
    "\n",
    "    if model_parameters.use_time:\n",
    "        time = patient_data[index][0].reshape((len(codes),))\n",
    "    else:\n",
    "        time = np.arange(len(codes))\n",
    "    for i in range(len(patient_data[0][0])):\n",
    "        visit_codes = codes[i]\n",
    "        visit_beta = betas[i]\n",
    "        visit_alpha = alphas[i][0]\n",
    "        relevant_indices = np.append(visit_codes,\n",
    "                                     range(model_parameters.num_codes+1,\n",
    "                                           model_parameters.num_codes+1+model_parameters.numeric_size))\\\n",
    "                                          .astype(np.int32)\n",
    "        values = np.full(fill_value='Diagnosed', shape=(len(visit_codes),))\n",
    "        if model_parameters.numeric_size:\n",
    "            visit_numerics = numerics[i]\n",
    "            values = np.append(values, visit_numerics)\n",
    "        values_mask = np.array([1. if value == 'Diagnosed' else value for value in values], dtype=np.float32)\n",
    "        beta_scaled = visit_beta * model_parameters.emb_weights[relevant_indices]\n",
    "        output_scaled = np.dot(beta_scaled, model_parameters.output_weights)\n",
    "        alpha_scaled = values_mask * visit_alpha * output_scaled\n",
    "        df_visit = pd.DataFrame({'status':values,\n",
    "                                 'feature': [dictionary[index] for index in relevant_indices],\n",
    "                                 'importance_feature':alpha_scaled[:, 0],\n",
    "                                 'importance_visit':visit_alpha,\n",
    "                                 'to_event':time[i]},\n",
    "                                columns=['status', 'feature', 'importance_feature',\n",
    "                                         'importance_visit', 'to_event'])\n",
    "        df_visit = df_visit[df_visit['feature'] != 'PADDING']\n",
    "        df_visit.sort_values(['importance_feature'], ascending=False, inplace=True)\n",
    "        importances.append(df_visit)\n",
    "\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data, model_parameters, ARGS):\n",
    "    \"\"\"Get Model Predictions\"\"\"\n",
    "    test_generator = SequenceBuilder(data, model_parameters, ARGS)\n",
    "    preds = model.predict_generator(generator=test_generator, max_queue_size=15,\n",
    "                                    use_multiprocessing=True, verbose=1, workers=3)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predictions(patient_id):\n",
    "    patient_data = data_generator.__getitem__(patient_id)\n",
    "    proba, alphas, betas = model_with_attention.predict_on_batch(patient_data)\n",
    "    visits = get_importances(alphas[0], betas[0], patient_data, model_parameters, dictionary)\n",
    "    for visit in visits:\n",
    "        print(visit)\n",
    "        \n",
    "def parse_arguments(parser):\n",
    "    \"\"\"Read user arguments\"\"\"\n",
    "    parser.add_argument('--path_model',\n",
    "                        type=str, default='Model/weights.03.hdf5',\n",
    "                        help='Path to the model to evaluate')\n",
    "    parser.add_argument('--path_data', type=str, default='data/data_test.pkl',\n",
    "                        help='Path to evaluation data')\n",
    "    parser.add_argument('--path_dictionary', type=str, default='data/dictionary.pkl',\n",
    "                        help='Path to codes dictionary')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='Batch size for initial probability predictions')\n",
    "    parser.add_argument('--path_target', type=str, default='data/target_test.pkl',\n",
    "                        help='Path to target data')\n",
    "    # parser.add_argument('--id', type=int, default=0,\n",
    "    #                     help='Id of the patient being interpreted')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(ARGS):\n",
    "    \"\"\"Main Body of the code\"\"\"\n",
    "    print('Loading Model and Extracting Parameters')\n",
    "    global model_with_attention\n",
    "    global model_parameters\n",
    "    global dictionary\n",
    "    model, model_with_attention = import_model(ARGS.path_model)\n",
    "    model_parameters = get_model_parameters(model)\n",
    "    print('Reading Data')\n",
    "    data, dictionary = read_data(model_parameters, ARGS.path_data, ARGS.path_dictionary)\n",
    "    global data_generator\n",
    "    data_generator = SequenceBuilder(data, model_parameters, ARGS)\n",
    "    global probabilities\n",
    "    probabilities = get_predictions(model, data, model_parameters, ARGS)\n",
    "    model.summary()\n",
    "    ARGS.batch_size = 1\n",
    "    data_generator = SequenceBuilder(data, model_parameters, ARGS)\n",
    "    \n",
    "    target = pd.read_pickle(ARGS.path_target)\n",
    "    expected_target = target['target'].values\n",
    "    print(expected_target)\n",
    "    for patient_id in range(0,10):\n",
    "        print('Patient\\'s '+str(patient_id)+' probability: {}'.format(probabilities[patient_id, 0, 0]))\n",
    "        print('Patient\\'s '+str(patient_id)+' expected target: '+str(expected_target[patient_id]))\n",
    "        #output_predictions(patient_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']\n",
    "def run():\n",
    "    PARSER = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    ARGS = parse_arguments(PARSER)\n",
    "    main(ARGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model and Extracting Parameters\n",
      "[<tf.Tensor 'time_distributed_out/Reshape_1:0' shape=(?, 1, 1) dtype=float32>]\n",
      "Model bias: [-1.3316513]\n",
      "Reading Data\n",
      "188/188 [==============================] - 4s 21ms/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "codes_input (InputLayer)        (None, None, None)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, None, 2 14000       codes_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 200)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "numeric_input (InputLayer)      (None, None, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "catInp (Concatenate)            (None, None, 203)    0           lambda_1[0][0]                   \n",
      "                                                                 numeric_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 203)    0           catInp[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "alpha (Bidirectional)           (None, None, 400)    646400      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dense_0 (TimeDistributed) (None, None, 1)      401         alpha[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "beta (Bidirectional)            (None, None, 400)    646400      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, None, 1)      0           alpha_dense_0[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "beta_dense_0 (TimeDistributed)  (None, None, 203)    81403       beta[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 203)    0           softmax_1[0][0]                  \n",
      "                                                                 beta_dense_0[0][0]               \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 203)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 203)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1, 203)       0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_out (TimeDistr (None, 1, 1)         204         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,388,808\n",
      "Trainable params: 1,388,808\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[0 0 0 ... 0 0 0]\n",
      "Patient's 0 probability: 0.2107093632221222\n",
      "Patient's 0 expected target: 0\n",
      "Patient's 1 probability: 0.22791354358196259\n",
      "Patient's 1 expected target: 0\n",
      "Patient's 2 probability: 0.2792239487171173\n",
      "Patient's 2 expected target: 0\n",
      "Patient's 3 probability: 0.3662487268447876\n",
      "Patient's 3 expected target: 0\n",
      "Patient's 4 probability: 0.9273985028266907\n",
      "Patient's 4 expected target: 1\n",
      "Patient's 5 probability: 0.3855116367340088\n",
      "Patient's 5 expected target: 0\n",
      "Patient's 6 probability: 0.9359851479530334\n",
      "Patient's 6 expected target: 1\n",
      "Patient's 7 probability: 0.9262168407440186\n",
      "Patient's 7 expected target: 1\n",
      "Patient's 8 probability: 0.29267746210098267\n",
      "Patient's 8 expected target: 0\n",
      "Patient's 9 probability: 0.40177300572395325\n",
      "Patient's 9 expected target: 0\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.401773\n"
     ]
    }
   ],
   "source": [
    "print(str(probabilities[9,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
