{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'gfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a97a1fd9b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# We use our \"load_graph\" function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Model/output_graph.pb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# We can verify that we can access the list of operations in the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9a97a1fd9b53>\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m(frozen_graph_filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# We load the protobuf file from the disk and parse it to retrieve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# unserialized graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozen_graph_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'gfile'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we can use again a convenient built-in function to import a graph_def into the \n",
    "    # current default Graph\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def, \n",
    "            return_elements=None, \n",
    "            name=\"prefix\", \n",
    "            op_dict=None, \n",
    "            producer_op_list=None\n",
    "        )\n",
    "    return graph\n",
    "\n",
    "# We use our \"load_graph\" function\n",
    "graph = load_graph(\"./Model/output_graph.pb\")\n",
    "\n",
    "# We can verify that we can access the list of operations in the graph\n",
    "for op in graph.get_operations():\n",
    "    print(op.name)     # <--- printing the operations snapshot below\n",
    "    # prefix/Placeholder/inputs_placeholder\n",
    "    # ...\n",
    "    # prefix/Accuracy/predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = graph.get_tensor_by_name(\"prefix/time_distributed_out/Reshape_1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = graph.get_tensor_by_name(\"prefix/codes_input:0\")\n",
    "z = graph.get_tensor_by_name(\"prefix/numeric_input:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randint\n",
    "from random import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "def get_rand_visit_codes():\n",
    "    #num_of_codes_in_visit = randint(1,5)\n",
    "    #visit_c = random.sample(range(0,68), num_of_codes_in_visit)\n",
    "    num_of_codes_in_visit = 2\n",
    "    visit_c = []\n",
    "    #print (visit_c)\n",
    "    return visit_c\n",
    "ite_rand = 0\n",
    "def get_rand_visit_numerics():\n",
    "    #[Diastolic,Systolic, pulse]\n",
    "    global ite_rand\n",
    "    if ite_rand == 0:\n",
    "        visit_n = [uniform(60,90),uniform(90,160),uniform(60,100)]\n",
    "    else:\n",
    "        visit_n = [uniform(90,110),uniform(160,180),uniform(100,120)]\n",
    "    #print (visit_n)\n",
    "    return visit_n\n",
    "\n",
    "def create_patient():\n",
    "    num_of_visits = randint(1,25)\n",
    "    global ite_rand\n",
    "    if ite_rand == 0:\n",
    "        ite_rand = 1\n",
    "    else:\n",
    "        ite_rand = 0\n",
    "    anomaly_patient_count = 0\n",
    "    patient_c = []\n",
    "    for k in range(0,num_of_visits,1):\n",
    "        patient_c.append(get_rand_visit_codes())\n",
    "    #print (patient_c)\n",
    "\n",
    "    patient_n = []\n",
    "    for k in range(0,num_of_visits,1):\n",
    "        visit_numerics = get_rand_visit_numerics()\n",
    "        patient_n.append(visit_numerics)\n",
    "        anomaly_patient_count = anomaly_patient_count + validate_numerics_for_anomaly(visit_numerics)\n",
    "        \n",
    "    #print (\"New patient \"+str(len(target))+\", # of visits: \"+str(num_of_visits))\n",
    "    #print (\"Number of anomalies: \"+ str(anomaly_patient_count))\n",
    "    target = 0\n",
    "    if anomaly_patient_count/num_of_visits > 0.7:\n",
    "        target = 1\n",
    "        #print (\"Target: \"+ str(1))\n",
    "    else:\n",
    "        target = 0\n",
    "        #print (\"Target: \"+ str(0))\n",
    "    #print(\"Target value in list: \"+str(target[len(target)-1]))\n",
    "    return [patient_c,patient_n,None,anomaly_patient_count, target]\n",
    "\n",
    "def validate_numerics_for_anomaly(numerics):\n",
    "    #[Diastolic,Systolic, pulse]\n",
    "    if (numerics[0] >= 100 or numerics[0] <= 55):\n",
    "        return 1\n",
    "    elif (numerics[1] >= 170 or numerics[1] <= 85):\n",
    "        return 1\n",
    "    elif (numerics[2] >= 110 or numerics[2] <= 55):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_codes: [[], [], [], [], [], [], [], [], []]\n",
      "patient_nums: [[102.46265960976592, 161.84189726360853, 115.39472246221708], [106.2801928167619, 167.74015650997114, 111.20465593331818], [95.29400881447118, 170.94809228821745, 100.72956559377283], [99.16243317265884, 168.09953449994546, 107.04374832240916], [102.76409386803302, 169.57890467816887, 101.62492754919089], [98.91324652640172, 171.56279669060177, 103.69519025217396], [98.16321258143104, 162.80701742550076, 105.93718436218849], [92.28354669852581, 179.31458663745056, 103.57760785526487], [107.43176399679531, 164.16805439393883, 118.48160719314988]]\n",
      "patient_anomalies: 7\n",
      "patient_target: 1\n"
     ]
    }
   ],
   "source": [
    "patient_1 = create_patient()\n",
    "print(\"patient_codes: \"+ str(patient_1[0]))\n",
    "print(\"patient_nums: \"+ str(patient_1[1]))\n",
    "print(\"patient_anomalies: \" +str(patient_1[3]))\n",
    "print(\"patient_target: \" +str(patient_1[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_testing = {\n",
    "    x: [patient_1[0]],\n",
    "    z: [patient_1[1]]\n",
    "}\n",
    "sess= tf.Session(graph=graph)\n",
    "result=sess.run(y_pred, feed_dict=feed_dict_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.9258097]]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_codes: [[], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "patient_nums: [[81.58675497124098, 109.32976295134867, 84.14181249303995], [69.70657866154629, 159.0450610530469, 73.57852377636516], [75.7933196280955, 139.90656238995777, 63.1498977183786], [62.28691804163644, 98.95535128201709, 72.2688770696065], [82.74432291361533, 131.25142495212128, 74.32070503515453], [85.97603772498697, 107.22965844045324, 93.10421161588653], [65.8347055907382, 128.33669440414138, 88.05376522913136], [77.39557599293364, 145.62697610410976, 75.16783649729588], [70.86042000374712, 140.62867483053157, 61.439735795079514], [66.96611704174586, 153.86865525875675, 90.39236993622174], [73.40479378358742, 103.96368483319577, 60.71693068884196], [80.57610118482674, 120.7704191825938, 79.55084367645671], [67.82834755944212, 127.40556418491008, 93.80747288074107]]\n",
      "patient_anomalies: 0\n",
      "patient_target: 0\n"
     ]
    }
   ],
   "source": [
    "patient_2 = create_patient()\n",
    "print(\"patient_codes: \"+ str(patient_2[0]))\n",
    "print(\"patient_nums: \"+ str(patient_2[1]))\n",
    "print(\"patient_anomalies: \" +str(patient_2[3]))\n",
    "print(\"patient_target: \" +str(patient_2[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_testing = {\n",
    "    x: [patient_2[0]],\n",
    "    z: [patient_2[1]]\n",
    "}\n",
    "sess= tf.Session(graph=graph)\n",
    "result=sess.run(y_pred, feed_dict=feed_dict_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.24745676]]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
